<div class="module-bar" data-module="timing">
    <button class="module-bar-title">suitkaise.timing</button>
    <nav class="module-bar-nav">
        <a href="#timing-why" class="module-bar-link active" data-page="timing-why">why</a>
        <a href="#timing-quick-start" class="module-bar-link" data-page="timing-quick-start">quick start</a>
        <a href="#timing" class="module-bar-link" data-page="timing">how to use</a>
        <a href="#timing-how-it-works" class="module-bar-link" data-page="timing-how-it-works">how it works</a>
        <a href="#timing-examples" class="module-bar-link" data-page="timing-examples">examples</a>
        <a href="#timing-videos" class="module-bar-link" data-page="timing-videos">videos</a>
        <a href="#timing-learn" class="module-bar-link" data-page="timing-learn">learn</a>
    </nav>
</div>
<section class="module-page why-page">
    <h1>Why you should use <code><suitkaise-api>timing</suitkaise-api></code></h1>
    <h2>TLDR</h2>
    <ul>
        <li><strong>1-line setup</strong> - <code><suitkaise-api>@timethis</suitkaise-api></code>: 1 line. <code><suitkaise-api>with TimeThis()</suitkaise-api></code>: also 1 line.</li>
        <li><strong>Deep statistics</strong> - <code>mean</code>, <code>median</code>, <code>stdev</code>, <code>variance</code>, <code>percentiles</code> (way better than <code>timeit</code>)</li>
        <li><strong>Pause/resume</strong> - exclude user input or delays from measurements</li>
        <li><strong>Thread-safe</strong> - time concurrent operations without race conditions</li>
        <li><strong>Discard bad runs</strong> - throw away failed attempts without polluting stats</li>
        <li><strong>Rolling windows</strong> - bound memory in long-running processes</li>
        <li><strong>Threshold filtering</strong> - only record slow operations</li>
        <li><strong>Frozen snapshots</strong> - capture stats at a point in time</li>
        <li><strong>Native async support</strong> - <code><suitkaise-api>.asynced()</suitkaise-api></code> for async contexts</li>
    </ul>
    <hr>
    <p>I was so tired of using <code>time.time()</code>, running some code, calling <code>time.time()</code> again, and then subtracting the difference to get how long it took.</p>
    <pre><code class="language-python">start_time = time.time()

# some code

end_time = time.time()

time_taken = end_time - start_time</code></pre>
    <p>And it gets even more annoying when you need to time multiple things.</p>
    <pre><code class="language-python">start_time = time.time()
# some code
end_time = time.time()

time_taken = end_time - start_time

# then ...

start_time2 = time.time()
# some code
end_time2 = time.time()

time_taken2 = end_time2 - start_time2
# ...</code></pre>
    <p>Or when I wanted to time a specific function, I had to return the resulting time with it as a tuple.</p>
    <pre><code class="language-python">def my_function():
    start_time = time.time()

    # whatever the function actually does

    end_time = time.time()

    return function_result, end_time - start_time

# later...
result, time_taken = my_function()</code></pre>
    <p>Then I had to manually add the times to a list.</p>
    <pre><code class="language-python">times1.append(time_taken)</code></pre>
    <p>And then calculate stats.</p>
    <pre><code class="language-python">import statistics

mean = statistics.mean(times1)
median = statistics.median(times1)</code></pre>
    <p>And you have to do this for every function you need to time.</p>
    <pre><code class="language-python">times2.append(time_taken)

times3.append(time_taken)

# and so on...</code></pre>
    <p>I wanted a super quick way to do this, that also made sense.</p>
    <p><strong>Result:</strong></p>
    <ul>
        <li>100% coverage of your code (you can time anything and everything)</li>
        <li>1-line setup</li>
        <li>Thread safety</li>
        <li>Deep statistical analysis, much better than <code>timeit</code></li>
        <li>Native async support</li>
    </ul>
    <h2><code><suitkaise-api>@timethis</suitkaise-api></code> decorator</h2>
    <p><strong>Without it</strong> - <em>7 lines</em></p>
    <pre><code class="language-python">import time # 1
from typing import Any

times_my_function = [] # 2

def my_function() -&gt; tuple[Any, float]:
    start_time = time.time() # 3

    # whatever the function actually does

    end_time = time.time() # 4

    return function_result, end_time - start_time # 5

result, time_taken = my_function() # 6

times_my_function.append(time_taken) # 7</code></pre>
    <p><strong>With <code><suitkaise-api>timing</suitkaise-api></code></strong> - <em>2 lines</em></p>
    <pre><code class="language-python">from <suitkaise-api>suitkaise</suitkaise-api>.<suitkaise-api>timing</suitkaise-api> import <suitkaise-api>timethis</suitkaise-api> # 1

<suitkaise-api>@timethis()</suitkaise-api> # 2
def my_function():

    # whatever the function actually does

    return result

result = my_function()</code></pre>
    <ul>
        <li>You can just slap <code><suitkaise-api>@timethis()</suitkaise-api></code> on any function you need to time</li>
        <li>Stored as a property of the function</li>
        <li>Don&#x27;t have to edit a function to time it</li>
    </ul>
    <h2><code><suitkaise-api>TimeThis</suitkaise-api></code> context manager</h2>
    <p>This covers everything that <code><suitkaise-api>@timethis</suitkaise-api></code> doesn&#x27;t in a context manager pattern.</p>
    <p><strong>Without it</strong> - <em>6 lines</em></p>
    <pre><code class="language-python">import time # 1

times = [] # 2

start_time = time.time() # 3

# whatever you need to time

end_time = time.time() # 4

time_taken = end_time - start_time # 5
times.append(time_taken) # 6</code></pre>
    <p><strong>With <code><suitkaise-api>timing</suitkaise-api></code></strong> - <em>2 lines</em></p>
    <pre><code class="language-python">from <suitkaise-api>suitkaise</suitkaise-api>.<suitkaise-api>timing</suitkaise-api> import <suitkaise-api>TimeThis</suitkaise-api> # 1

with <suitkaise-api>TimeThis(</suitkaise-api>) as timer: # 2

    # whatever you need to time

time_taken = <suitkaise-api>timer</suitkaise-api>.<suitkaise-api>most_recent</suitkaise-api> # 3</code></pre>
    <ul>
        <li>No manual tracking</li>
        <li>Context manager makes it clear what is being timed</li>
        <li>Error-proof</li>
        <li>Clear indication of what is being timed</li>
    </ul>
    <h2>Deep Statistical Analysis</h2>
    <p><code>timeit</code> gives you a single number. That&#x27;s not enough.</p>
    <p>You need mean, median, standard deviation, variance, and percentiles to actually understand performance.</p>
    <p><strong>Without it</strong> - <em>10+ lines</em></p>
    <pre><code class="language-python">import time # 1
import statistics # 2

times = [] # 3

for i in range(100):
    start = time.perf_counter() # 4
    do_work()
    end = time.perf_counter() # 5
    times.append(end - start) # 6

mean = statistics.mean(times) # 7
median = statistics.median(times) # 8
stdev = statistics.stdev(times) # 9

# percentiles? have fun
sorted_times = sorted(times) # 10
p95 = sorted_times[int(0.95 * len(sorted_times))] # 11

# and more stats calculations...</code></pre>
    <p><strong>With <code><suitkaise-api>timing</suitkaise-api></code></strong> - <em>2 lines</em></p>
    <pre><code class="language-python">from <suitkaise-api>suitkaise</suitkaise-api> import <suitkaise-api>timing</suitkaise-api> # 1

for i in range(100):
    with <suitkaise-api>timing</suitkaise-api>.<suitkaise-api>TimeThis(</suitkaise-api>) as timer: # 2
        do_work()

# all statistics automatically available, no extra work
<suitkaise-api>timer</suitkaise-api>.<suitkaise-api>mean</suitkaise-api>
<suitkaise-api>timer</suitkaise-api>.<suitkaise-api>median</suitkaise-api>
<suitkaise-api>timer</suitkaise-api>.<suitkaise-api>stdev</suitkaise-api>
<suitkaise-api>timer</suitkaise-api>.<suitkaise-api>variance</suitkaise-api>
<suitkaise-api>timer</suitkaise-api>.<suitkaise-api>min</suitkaise-api>
<suitkaise-api>timer</suitkaise-api>.<suitkaise-api>max</suitkaise-api>
<suitkaise-api>timer</suitkaise-api>.<suitkaise-api>percentile</suitkaise-api>(95)
<suitkaise-api>timer</suitkaise-api>.<suitkaise-api>percentile</suitkaise-api>(99)</code></pre>
    <p>One object. Every stat you could want. No manual calculation.</p>
    <h2>Pause and Resume</h2>
    <p>You&#x27;re timing a database query, but you need to ask the user something in the middle.</p>
    <p><strong>Without it</strong></p>
    <pre><code class="language-python">import time

start = time.perf_counter()

results = database.query(&quot;SELECT * FROM users&quot;)

# pause timing... manually?
pause_start = time.perf_counter()
user_input = input(&quot;Export to CSV? (y/n): &quot;)
pause_end = time.perf_counter()
pause_duration = pause_end - pause_start

if user_input == &#x27;y&#x27;:
    export_to_csv(results)

end = time.perf_counter()

# manually subtract pause time
elapsed = (end - start) - pause_duration</code></pre>
    <p><strong>With <code><suitkaise-api>timing</suitkaise-api></code></strong></p>
    <pre><code class="language-python">from <suitkaise-api>suitkaise</suitkaise-api> import <suitkaise-api>timing</suitkaise-api>

timer = <suitkaise-api>timing</suitkaise-api>.<suitkaise-api>Sktimer(</suitkaise-api>)
<suitkaise-api>timer</suitkaise-api>.<suitkaise-api>start</suitkaise-api>()

results = database.query(&quot;SELECT * FROM users&quot;)

<suitkaise-api>timer</suitkaise-api>.<suitkaise-api>pause</suitkaise-api>()
user_input = input(&quot;Export to CSV? (y/n): &quot;)
<suitkaise-api>timer</suitkaise-api>.<suitkaise-api>resume</suitkaise-api>()

if user_input == &#x27;y&#x27;:
    export_to_csv(results)

elapsed = <suitkaise-api>timer</suitkaise-api>.<suitkaise-api>stop</suitkaise-api>()  # user input time excluded</code></pre>
    <p><code><suitkaise-api>pause</suitkaise-api>()</code> and <code><suitkaise-api>resume</suitkaise-api>()</code>. That&#x27;s it. The timer handles the math.</p>
    <h2>Discard Bad Measurements</h2>
    <p>Sometimes things fail. You don&#x27;t want failed attempts polluting your statistics.</p>
    <p><strong>Without it</strong></p>
    <pre><code class="language-python">times = []

for i in range(100):
    start = time.perf_counter()
    try:
        result = unreliable_operation()
        end = time.perf_counter()
        times.append(end - start)
    except Exception:
        pass  # awkward - start was recorded, now what?</code></pre>
    <p><strong>With <code><suitkaise-api>timing</suitkaise-api></code></strong></p>
    <pre><code class="language-python">timer = <suitkaise-api>timing</suitkaise-api>.<suitkaise-api>Sktimer(</suitkaise-api>)

for i in range(100):
    <suitkaise-api>timer</suitkaise-api>.<suitkaise-api>start</suitkaise-api>()
    try:
        result = unreliable_operation()
        <suitkaise-api>timer</suitkaise-api>.<suitkaise-api>stop</suitkaise-api>()  # success - record it
    except Exception:
        <suitkaise-api>timer</suitkaise-api>.<suitkaise-api>discard</suitkaise-api>()  # failure - forget it

# statistics only reflect successful operations</code></pre>
    <p><code><suitkaise-api>discard</suitkaise-api>()</code> cleanly abandons the measurement. Your stats stay clean.</p>
    <h2>Thread Safety</h2>
    <p>Multiple threads timing the same thing? No problem.</p>
    <pre><code class="language-python">timer = <suitkaise-api>timing</suitkaise-api>.<suitkaise-api>Sktimer(</suitkaise-api>)  # thread-safe by default

def worker():
    for _ in range(100):
        <suitkaise-api>timer</suitkaise-api>.<suitkaise-api>start</suitkaise-api>()
        do_work()
        <suitkaise-api>timer</suitkaise-api>.<suitkaise-api>stop</suitkaise-api>()

# spawn 4 threads...
# stats just work
print(<suitkaise-api>timer</suitkaise-api>.<suitkaise-api>mean</suitkaise-api>)</code></pre>
    <p><code><suitkaise-api>Sktimer</suitkaise-api></code> is thread-safe out of the box. Each thread gets its own session. Results aggregate automatically.</p>
    <h2>Lap Timing</h2>
    <p>Timing items in a loop? <code><suitkaise-api>lap</suitkaise-api>()</code> is stop + start in one call.</p>
    <p><strong>Without it</strong></p>
    <pre><code class="language-python">times = []
start = time.perf_counter()

for item in items:
    process(item)
    now = time.perf_counter()
    times.append(now - start)
    start = now  # easy to forget this</code></pre>
    <p><strong>With <code><suitkaise-api>timing</suitkaise-api></code></strong></p>
    <pre><code class="language-python">timer = <suitkaise-api>timing</suitkaise-api>.<suitkaise-api>Sktimer(</suitkaise-api>)
<suitkaise-api>timer</suitkaise-api>.<suitkaise-api>start</suitkaise-api>()

for item in items:
    process(item)
    <suitkaise-api>timer</suitkaise-api>.<suitkaise-api>lap</suitkaise-api>()  # records time, continues timing

<suitkaise-api>timer</suitkaise-api>.<suitkaise-api>discard</suitkaise-api>()  # clean up the last pending measurement</code></pre>
    <h2>Rolling Windows</h2>
    <p>Long-running server? Can&#x27;t keep every measurement forever.</p>
    <p><strong>Without it</strong></p>
    <pre><code class="language-python">from collections import deque

MAX_TIMES = 1000
times = deque(maxlen=MAX_TIMES)
lock = threading.Lock()

# now manually manage this everywhere</code></pre>
    <p><strong>With <code><suitkaise-api>timing</suitkaise-api></code></strong></p>
    <pre><code class="language-python">timer = <suitkaise-api>timing</suitkaise-api>.<suitkaise-api>Sktimer(</suitkaise-api>max_times=1000)

# that&#x27;s it - automatically keeps only the last 1000 measurements</code></pre>
    <p>One parameter. Memory bound. Statistics always reflect recent performance.</p>
    <h2>Threshold Filtering</h2>
    <p>Only care about slow operations? Filter out the fast ones automatically.</p>
    <pre><code class="language-python"><suitkaise-api>@timing</suitkaise-api>.<suitkaise-api>timethis</suitkaise-api>(threshold=0.1)
def handle_request():
    # only records times &gt;= 0.1 seconds
    ...</code></pre>
    <p>Fast operations are silently discarded. Your statistics focus on what matters.</p>
    <h2>Stacked Decorators</h2>
    <p>Want both combined stats AND per-function stats?</p>
    <pre><code class="language-python">perf_timer = <suitkaise-api>timing</suitkaise-api>.<suitkaise-api>Sktimer(</suitkaise-api>)

<suitkaise-api>@timing</suitkaise-api>.<suitkaise-api>timethis</suitkaise-api>()             # per-function timer
<suitkaise-api>@timing</suitkaise-api>.<suitkaise-api>timethis</suitkaise-api>(perf_timer)   # shared timer
def db_read():
    # your code here

<suitkaise-api>@timing</suitkaise-api>.<suitkaise-api>timethis</suitkaise-api>()             # per-function timer
<suitkaise-api>@timing</suitkaise-api>.<suitkaise-api>timethis</suitkaise-api>(perf_timer)   # shared timer
def db_write():
    # your code here

# combined stats
print(perf_timer.mean)

# individual stats
print(db_read.<suitkaise-api>timer</suitkaise-api>.<suitkaise-api>mean</suitkaise-api>)
print(db_write.<suitkaise-api>timer</suitkaise-api>.<suitkaise-api>mean</suitkaise-api>)</code></pre>
    <p>Stack decorators. Each records independently. Zero manual list management.</p>
    <h2>Frozen Snapshots</h2>
    <p>Need to capture statistics at a point in time?</p>
    <pre><code class="language-python">snapshot = <suitkaise-api>timer</suitkaise-api>.get_statistics()

# timer continues recording...
<suitkaise-api>timer</suitkaise-api>.<suitkaise-api>start</suitkaise-api>()
do_more_work()
<suitkaise-api>timer</suitkaise-api>.<suitkaise-api>stop</suitkaise-api>()

# snapshot still has the old values
print(snapshot.mean)  # unchanged</code></pre>
    <p><code>get_statistics()</code> returns an immutable <code>TimerStats</code> object. Perfect for logging or reporting.</p>
    <h2><code><suitkaise-api>elapsed</suitkaise-api>()</code> Just Works</h2>
    <p>Order doesn&#x27;t matter. Always returns positive.</p>
    <pre><code class="language-python">from <suitkaise-api>suitkaise</suitkaise-api> import <suitkaise-api>timing</suitkaise-api>

start = <suitkaise-api>timing</suitkaise-api>.time()
<suitkaise-api>timing</suitkaise-api>.sleep(1)
end = <suitkaise-api>timing</suitkaise-api>.time()

<suitkaise-api>timing</suitkaise-api>.<suitkaise-api>elapsed</suitkaise-api>(start, end)  # 1.0
<suitkaise-api>timing</suitkaise-api>.<suitkaise-api>elapsed</suitkaise-api>(end, start)  # 1.0 (same!)
<suitkaise-api>timing</suitkaise-api>.<suitkaise-api>elapsed</suitkaise-api>(start)       # uses current time</code></pre>
    <p>No more <code>abs()</code> everywhere. No more &quot;which one was first?&quot; bugs.</p>
    <h2>Async Support</h2>
    <pre><code class="language-python"># sync
<suitkaise-api>timing</suitkaise-api>.sleep(1)

# async
await <suitkaise-api>timing</suitkaise-api>.sleep.asynced()(1)</code></pre>
    <p>Same API. Just add <code><suitkaise-api>.asynced()</suitkaise-api></code> when you need it.</p>
    <p>This works with <code><suitkaise-api>TimeThis</suitkaise-api></code> too:</p>
    <pre><code class="language-python">async def fetch_all():
    async with <suitkaise-api>TimeThis(</suitkaise-api>) as timer:
        await fetch_users()
        await fetch_orders()
    
    print(f&quot;Total: {timer.most_recent:.3f}s&quot;)</code></pre>
    <p>And with <code><suitkaise-api>@timethis</suitkaise-api></code>:</p>
    <pre><code class="language-python"><suitkaise-api>@timethis</suitkaise-api>()
async def fetch_data():
    async with aiohttp.ClientSession() as session:
        return await session.get(&quot;https://api.example.com&quot;)

await fetch_data()
print(fetch_data.<suitkaise-api>timer</suitkaise-api>.<suitkaise-api>mean</suitkaise-api>)</code></pre>
    <p>Sync and async, same interface. No separate implementations needed.</p>
    <h2>Works with <code><suitkaise-api>Share</suitkaise-api></code> â€” timing across processes</h2>
    <p><code><suitkaise-api>Sktimer</suitkaise-api></code> works natively inside <code><suitkaise-api>Share</suitkaise-api></code>. This means you can aggregate timing data across multiple processes without any extra code.</p>
    <pre><code class="language-python">from <suitkaise-api>suitkaise</suitkaise-api>.<suitkaise-api>processing</suitkaise-api> import <suitkaise-api>Share</suitkaise-api>, <suitkaise-api>Pool</suitkaise-api>, <suitkaise-api>Skprocess</suitkaise-api>
from <suitkaise-api>suitkaise</suitkaise-api>.<suitkaise-api>timing</suitkaise-api> import <suitkaise-api>Sktimer</suitkaise-api>

<suitkaise-api>share</suitkaise-api> = <suitkaise-api>Share(</suitkaise-api>)
<suitkaise-api>share.timer</suitkaise-api> = <suitkaise-api>Sktimer(</suitkaise-api>)

class <suitkaise-api>TimedWorker</suitkaise-api>(<suitkaise-api>Skprocess</suitkaise-api>):
    def __init__(self, share, data):
        self.share = share
        self.data = data
        self.<suitkaise-api>process_config</suitkaise-api>.<suitkaise-api>runs</suitkaise-api> = 1

    def <suitkaise-api>__run__</suitkaise-api>(self):
        self.<suitkaise-api>share.timer</suitkaise-api>.<suitkaise-api>start</suitkaise-api>()
        process(self.data)
        self.<suitkaise-api>share.timer</suitkaise-api>.<suitkaise-api>stop</suitkaise-api>()

<suitkaise-api>pool</suitkaise-api> = <suitkaise-api>Pool(</suitkaise-api>workers=4)
<suitkaise-api>pool.star()</suitkaise-api>.<suitkaise-api>map</suitkaise-api>(<suitkaise-api>TimedWorker</suitkaise-api>, [(share, item) for item in work_items])

# all 4 processes contributed to the same timer
print(f&quot;Mean across all workers: {share.timer.mean:.3f}s&quot;)
print(f&quot;p95 across all workers: {share.timer.percentile(95):.3f}s&quot;)</code></pre>
    <p>Every process writes to the same timer. Stats aggregate automatically. No manual list management, no locks, no merging results.</p>
    <p><code><suitkaise-api>Skprocess</suitkaise-api></code> also has built-in timers for every lifecycle method -- access them via <code><suitkaise-api>process.__run__</suitkaise-api>.<suitkaise-api>timer</suitkaise-api></code>, <code><suitkaise-api>process.__prerun__</suitkaise-api>.<suitkaise-api>timer</suitkaise-api></code>, etc. These are <code><suitkaise-api>Sktimer</suitkaise-api></code> objects with all the same statistical depth.</p>
</section>
