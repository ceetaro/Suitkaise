<div class="module-bar" data-module="sk">
    <button class="module-bar-title">suitkaise.sk</button>
    <nav class="module-bar-nav">
        <a href="#sk-why" class="module-bar-link" data-page="sk-why">why</a>
        <a href="#sk-quick-start" class="module-bar-link" data-page="sk-quick-start">quick start</a>
        <a href="#sk" class="module-bar-link" data-page="sk">how to use</a>
        <a href="#sk-how-it-works" class="module-bar-link" data-page="sk-how-it-works">how it works</a>
        <a href="#sk-examples" class="module-bar-link active" data-page="sk-examples">examples</a>
        <a href="#sk-blocking-calls" class="module-bar-link" data-page="sk-blocking-calls">blocking calls</a>
        <a href="#sk-videos" class="module-bar-link" data-page="sk-videos">videos</a>
        <a href="#sk-tests" class="module-bar-link" data-page="sk-tests">tests</a>
        <a href="#sk-learn" class="module-bar-link" data-page="sk-learn">learn</a>
    </nav>
</div>
<section class="module-page">
    <h1><code>sk</code> examples</h1>
    <details>
        <summary>Basic examples</summary>
        <div class="dropdown-content">
    <h3>Decorate a function</h3>
    <pre><code class="language-python">from suitkaise import sk
from pathlib import Path
import json

@sk
def load_users(path: Path) -&gt; list[dict]:
    data = json.loads(Path(path).read_text())
    return data[&quot;users&quot;]

# real file I/O
data_path = Path(&quot;data/users.json&quot;)
data_path.parent.mkdir(parents=True, exist_ok=True)
data_path.write_text(json.dumps({&quot;users&quot;: [{&quot;id&quot;: 1, &quot;name&quot;: &quot;Ana&quot;}]}))

# call normally (no changes to calling style)
users = load_users(data_path)
print(users)  # [{&#x27;id&#x27;: 1, &#x27;name&#x27;: &#x27;Ana&#x27;}]</code></pre>
    <h3>Use <code>sk()</code> as a function</h3>
    <pre><code class="language-python">from suitkaise import sk

def streamline_format(text: str) -&gt; str:
    return text.strip().lower().replace(&quot; &quot;, &quot;-&quot;)

streamline_format = sk(streamline_format)

print(streamline_format(&quot;Hello World&quot;))  # &quot;hello-world&quot;</code></pre>
    <h3>Chaining modifiers (order does not matter)</h3>
    <pre><code class="language-python">from suitkaise import sk
from pathlib import Path
import hashlib

@sk
def read_and_hash(path: Path) -&gt; str:
    content = Path(path).read_bytes()
    return hashlib.sha256(content).hexdigest()

data_path = Path(&quot;data/blob.bin&quot;)
data_path.parent.mkdir(parents=True, exist_ok=True)
data_path.write_bytes(b&quot;real data&quot; * 100_000)

# same behavior, different order
digest = read_and_hash.retry(times=3, delay=0.1).timeout(1.0)(data_path)
digest = read_and_hash.timeout(1.0).retry(times=3, delay=0.1)(data_path)</code></pre>
    <h3>Timeout handling</h3>
    <pre><code class="language-python">from suitkaise import sk
from suitkaise.sk import FunctionTimeoutError

@sk
def count_primes(limit: int) -&gt; int:
    primes = []
    for n in range(2, limit):
        is_prime = True
        for p in primes:
            if p * p &gt; n:
                break
            if n % p == 0:
                is_prime = False
                break
        if is_prime:
            primes.append(n)
    return len(primes)

try:
    result = count_primes.timeout(0.05)(200_000)
except FunctionTimeoutError as exc:
    print(f&quot;Timed out: {exc}&quot;)</code></pre>
    <h3>Background execution (Future)</h3>
    <pre><code class="language-python">from suitkaise import sk
from pathlib import Path
import hashlib

@sk
def hash_file(path: Path) -&gt; str:
    data = Path(path).read_bytes()
    return hashlib.sha256(data).hexdigest()

data_path = Path(&quot;data/large.bin&quot;)
data_path.parent.mkdir(parents=True, exist_ok=True)
data_path.write_bytes(b&quot;x&quot; * 5_000_000)

future = hash_file.background()(data_path)

# do other work
summary = (data_path.stat().st_size, data_path.name)

# get the result (this will block)
result = future.result()
print(summary, result[:12])</code></pre>
    <h3>Rate limiting</h3>
    <pre><code class="language-python">from suitkaise import sk
from pathlib import Path

@sk
def file_size(path: Path) -&gt; int:
    return Path(path).stat().st_size

data_path = Path(&quot;data/sample.txt&quot;)
data_path.parent.mkdir(parents=True, exist_ok=True)
data_path.write_text(&quot;real content\n&quot; * 1000)

limited = file_size.rate_limit(2.0)  # max 2 calls per second
sizes = [limited(data_path) for _ in range(5)]
print(sizes)</code></pre>
    <h3>Custom retry exceptions</h3>
    <pre><code class="language-python">from suitkaise import sk
from pathlib import Path
import json

class ApiError(RuntimeError):
    pass

@sk
def load_config(path: Path) -&gt; dict:
    text = Path(path).read_text()
    try:
        return json.loads(text)
    except json.JSONDecodeError:
        # repair the file and retry
        Path(path).write_text(text + &quot;}&quot;)
        raise ApiError(&quot;Config was incomplete, repaired and retrying&quot;)

# create a truncated JSON file
config_path = Path(&quot;data/config.json&quot;)
config_path.parent.mkdir(parents=True, exist_ok=True)
config_path.write_text(&#x27;{&quot;name&quot;: &quot;demo&quot;&#x27;)

# only retry on ApiError
config = load_config.retry(times=2, delay=0.1, exceptions=(ApiError,))(config_path)
print(config)</code></pre>
        </div>
    </details>
    <details>
        <summary>Async examples</summary>
        <div class="dropdown-content">
    <h3><code>asynced()</code> for async code</h3>
    <pre><code class="language-python">import asyncio
from suitkaise import sk
from pathlib import Path
import csv

@sk
def sum_csv(path: Path) -&gt; int:
    total = 0
    with open(path, &quot;r&quot;, newline=&quot;&quot;) as f:
        reader = csv.reader(f)
        for row in reader:
            total += int(row[0])
    return total

# real CSV work
data_dir = Path(&quot;data&quot;)
data_dir.mkdir(parents=True, exist_ok=True)
paths = []
for i in range(3):
    p = data_dir / f&quot;numbers_{i}.csv&quot;
    p.write_text(&quot;\n&quot;.join(str(n) for n in range(1, 1000)))
    paths.append(p)

async def main():
    results = await asyncio.gather(
        sum_csv.asynced()(paths[0]),
        sum_csv.asynced()(paths[1]),
        sum_csv.asynced()(paths[2]),
    )
    print(results)

asyncio.run(main())</code></pre>
    <h3>Async chaining with timeout + retry</h3>
    <pre><code class="language-python">import asyncio
from suitkaise import sk
from pathlib import Path
import json

@sk
def load_report(path: Path) -&gt; dict:
    text = Path(path).read_text()
    try:
        return json.loads(text)
    except json.JSONDecodeError:
        # fix the file and retry
        Path(path).write_text(text + &quot;}&quot;)
        raise ValueError(&quot;Report was incomplete, repaired and retrying&quot;)

report_path = Path(&quot;data/report.json&quot;)
report_path.parent.mkdir(parents=True, exist_ok=True)
report_path.write_text(&#x27;{&quot;ok&quot;: true&#x27;)

async def main():
    report = await (
        load_report.asynced()
        .retry(times=2, delay=0.1, exceptions=(ValueError,))
        .timeout(0.5)
    )(report_path)
    print(report)

asyncio.run(main())</code></pre>
    <h3>Async rate limiting</h3>
    <pre><code class="language-python">import asyncio
from suitkaise import sk
from pathlib import Path
import hashlib

@sk
def hash_text(path: Path) -&gt; str:
    data = Path(path).read_text().encode()
    return hashlib.sha256(data).hexdigest()

data_path = Path(&quot;data/log.txt&quot;)
data_path.parent.mkdir(parents=True, exist_ok=True)
data_path.write_text(&quot;log line\n&quot; * 1000)

async def main():
    limited = hash_text.asynced().rate_limit(5.0)
    results = await asyncio.gather(*[limited(data_path) for _ in range(10)])
    print(results[:2])

asyncio.run(main())</code></pre>
        </div>
    </details>
    <details>
        <summary>Blocking detection</summary>
        <div class="dropdown-content">
    <h3>Inspect blocking calls</h3>
    <pre><code class="language-python">from suitkaise import sk
from pathlib import Path

@sk
def load_text(path: Path) -&gt; str:
    with open(path, &quot;r&quot;) as f:
        return f.read()

data_path = Path(&quot;data/readme.txt&quot;)
data_path.parent.mkdir(parents=True, exist_ok=True)
data_path.write_text(&quot;real text&quot;)

print(load_text.has_blocking_calls)  # True
print(load_text.blocking_calls)      # includes file I/O</code></pre>
    <h3>Mark CPU-heavy code with <code>@blocking</code></h3>
    <pre><code class="language-python">from suitkaise import sk, blocking

@sk
@blocking
def heavy_math(n: int) -&gt; int:
    return sum(range(n))

# background/asynced are now available
future = heavy_math.background()(1_000_000)
result = future.result()</code></pre>
        </div>
    </details>
    <details>
        <summary>Classes</summary>
        <div class="dropdown-content">
    <h3>Decorate a class</h3>
    <pre><code class="language-python">from suitkaise import sk
import json

@sk
class DataStore:
    def __init__(self):
        self.data = {}
    
    def set(self, key: str, value: dict):
        self.data[key] = value
    
    def save(self, path: str):
        with open(path, &quot;w&quot;) as f:
            f.write(json.dumps(self.data))

store = DataStore()
store.set(&quot;a&quot;, {&quot;value&quot;: 1})
store.save(&quot;output.json&quot;)

# modifiers on methods
store.save.timeout(2.0)(&quot;output.json&quot;)</code></pre>
    <h3>Class-level async</h3>
    <pre><code class="language-python">import asyncio
from suitkaise import sk, blocking
from pathlib import Path

@sk
class FileReader:
    @blocking
    def read(self, path: Path) -&gt; str:
        with open(path, &quot;r&quot;) as f:
            return f.read()

data_path = Path(&quot;data/message.txt&quot;)
data_path.parent.mkdir(parents=True, exist_ok=True)
data_path.write_text(&quot;hello from disk&quot;)

async def main():
    reader = FileReader()
    data = await reader.read.asynced()(data_path)
    print(data)

asyncio.run(main())</code></pre>
    <h3>Handling <code>SkModifierError</code> for classes without blocking calls</h3>
    <pre><code class="language-python">from suitkaise import sk
from suitkaise.sk import SkModifierError

@sk
class Counter:
    def __init__(self):
        self.value = 0
    
    def inc(self):
        self.value += 1

try:
    Counter.asynced()
except SkModifierError as exc:
    print(exc)</code></pre>
    <h3><code>Share</code> compatibility</h3>
    <pre><code class="language-python">from suitkaise import sk
from suitkaise.processing import Share

@sk
class Counter:
    def __init__(self):
        self.value = 0
    
    def inc(self):
        self.value += 1

with Share() as share:
    share.counter = Counter()
    share.counter.inc()
    share.counter.inc()
    print(share.counter.value)  # 2</code></pre>
        </div>
    </details>
    <details>
        <summary>Advanced examples</summary>
        <div class="dropdown-content">
    <h3>Combining retry + timeout + background</h3>
    <pre><code class="language-python">from suitkaise import sk
from pathlib import Path
import json

@sk
def load_payload(path: Path) -&gt; dict:
    text = Path(path).read_text()
    try:
        return json.loads(text)
    except json.JSONDecodeError:
        # repair the file, then retry
        Path(path).write_text(text + &quot;}&quot;)
        raise RuntimeError(&quot;Payload incomplete, repaired and retrying&quot;)

payload_path = Path(&quot;data/payload.json&quot;)
payload_path.parent.mkdir(parents=True, exist_ok=True)
payload_path.write_text(&#x27;{&quot;id&quot;: 1, &quot;value&quot;: 42&#x27;)

future = load_payload.retry(times=2, delay=0.1).timeout(1.0).background()(payload_path)
print(future.result())</code></pre>
    <h3>Rate limiting shared across wrappers</h3>
    <pre><code class="language-python">from suitkaise import sk
from pathlib import Path

@sk
def read_lines(path: Path) -&gt; int:
    return len(Path(path).read_text().splitlines())

log_path = Path(&quot;data/log.txt&quot;)
log_path.parent.mkdir(parents=True, exist_ok=True)
log_path.write_text(&quot;line\n&quot; * 500)

# limiter lives inside the wrapper
limited = read_lines.rate_limit(3.0)

batch_a = [limited(log_path) for _ in range(3)]
batch_b = [limited(log_path) for _ in range(3)]
print(batch_a + batch_b)</code></pre>
        </div>
    </details>
    <h2>Full script using <code>sk</code> modifiers</h2>
    <p>An end-to-end example that uses multiple modifiers together:</p>
    <ul>
        <li><code>asynced()</code> for concurrent fetches</li>
        <li><code>retry()</code> for transient failures</li>
        <li><code>timeout()</code> to cap long calls</li>
        <li><code>rate_limit()</code> to protect external services</li>
        <li><code>background()</code> for CPU-heavy scoring</li>
        <li><code>@blocking</code> to mark CPU-bound work</li>
    </ul>
    <pre><code class="language-python">&quot;&quot;&quot;
End-to-end sk modifiers example.

Parses in-memory JSON records, repairs incomplete inputs, scores them in
background, and returns scored records.
&quot;&quot;&quot;

import asyncio
import json
import hashlib

from suitkaise import sk, blocking
from suitkaise.sk import FunctionTimeoutError


class TransientError(RuntimeError):
    pass


def seed_records() -&gt; list[str]:
    &quot;&quot;&quot;Create a mix of valid and truncated JSON payloads.&quot;&quot;&quot;
    payloads = []
    for record_id in range(1, 11):
        record = {&quot;id&quot;: record_id, &quot;value&quot;: record_id * 3}
        text = json.dumps(record)
        if record_id == 4:
            text = text[:-1]  # truncate one payload to trigger repair
        payloads.append(text)
    return payloads


@sk
@blocking
def load_record(index: int, payloads: list[str]) -&gt; dict:
    text = payloads[index]
    try:
        record = json.loads(text)
    except json.JSONDecodeError:
        # repair and retry in memory
        payloads[index] = text + &quot;}&quot;
        raise TransientError(&quot;Record incomplete, repaired and retrying&quot;)
    
    if &quot;id&quot; not in record or &quot;value&quot; not in record:
        raise ValueError(&quot;Missing required keys&quot;)
    
    return record


@sk
@blocking
def score_record(record: dict) -&gt; dict:
    payload = f&quot;{record[&#x27;id&#x27;]}:{record[&#x27;value&#x27;]}&quot;.encode()
    digest = hashlib.sha256(payload).hexdigest()
    score = int(digest[:8], 16) % 1000
    return {**record, &quot;score&quot;: score}


async def main():
    payloads = seed_records()
    
    loader = (
        load_record.asynced()
        .retry(times=2, delay=0.1, exceptions=(TransientError,))
        .timeout(0.5)
        .rate_limit(20.0)
    )
    
    results = await asyncio.gather(
        *[loader(i, payloads) for i in range(len(payloads))],
        return_exceptions=True,
    )
    
    records = []
    for idx, result in enumerate(results):
        if isinstance(result, FunctionTimeoutError):
            print(f&quot;Timeout: record {idx + 1}&quot;)
            continue
        if isinstance(result, Exception):
            print(f&quot;Failed: record {idx + 1}: {result}&quot;)
            continue
        records.append(result)
    
    futures = [score_record.background()(record) for record in records]
    scored = [future.result() for future in futures]
    
    print(f&quot;Scored {len(scored)} records&quot;)
    print(&quot;Sample:&quot;, scored[:3])


if __name__ == &quot;__main__&quot;:
    asyncio.run(main())</code></pre>
</section>
