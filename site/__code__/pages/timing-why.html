<div class="module-bar" data-module="timing">
    <button class="module-bar-title">suitkaise.timing</button>
    <nav class="module-bar-nav">
        <a href="#timing-why" class="module-bar-link active" data-page="timing-why">why</a>
        <a href="#timing-quick-start" class="module-bar-link" data-page="timing-quick-start">quick start</a>
        <a href="#timing" class="module-bar-link" data-page="timing">how to use</a>
        <a href="#timing-how-it-works" class="module-bar-link" data-page="timing-how-it-works">how it works</a>
        <a href="#timing-examples" class="module-bar-link" data-page="timing-examples">examples</a>
        <a href="#timing-videos" class="module-bar-link" data-page="timing-videos">videos</a>
        <a href="#timing-tests" class="module-bar-link" data-page="timing-tests">tests</a>
        <a href="#timing-learn" class="module-bar-link" data-page="timing-learn">learn</a>
    </nav>
</div>
<section class="module-page why-page">
    <h1>Why you should use <code>timing</code></h1>
    <h2>TLDR</h2>
    <ul>
        <li><strong>1-line setup</strong> - <code>@timethis()</code> or <code>with TimeThis()</code>, done</li>
        <li><strong>Deep statistics</strong> - mean, median, stdev, variance, percentiles (way better than <code>timeit</code>)</li>
        <li><strong>Pause/resume</strong> - exclude user input or delays from measurements</li>
        <li><strong>Thread-safe</strong> - time concurrent operations without race conditions</li>
        <li><strong>Discard bad runs</strong> - throw away failed attempts without polluting stats</li>
        <li><strong>Rolling windows</strong> - bound memory in long-running processes</li>
        <li><strong>Threshold filtering</strong> - only record slow operations</li>
        <li><strong>Frozen snapshots</strong> - capture stats at a point in time</li>
        <li><strong>Native async support</strong> - <code>.asynced()</code> for async contexts</li>
    </ul>
    <hr>
    <p>I was so tired of using <code>time.time()</code>, running some code, calling <code>time.time()</code> again, and then subtracting the difference to get how long it took.</p>
    <pre><code class="language-python">start_time = time.time()

# some code

end_time = time.time()

time_taken = end_time - start_time</code></pre>
    <p>And it gets even more annoying when you need to time multiple things.</p>
    <pre><code class="language-python">start_time = time.time()
# some code
end_time = time.time()

time_taken = end_time - start_time

# then ...

start_time2 = time.time()
# some code
end_time2 = time.time()

time_taken2 = end_time2 - start_time2
# ...</code></pre>
    <p>Or when I wanted to time a specific function, I had to return the resulting time with it as a tuple.</p>
    <pre><code class="language-python">def my_function():
    start_time = time.time()

    # whatever the function actually does

    end_time = time.time()

    return function_result, end_time - start_time

# later...
result, time_taken = my_function()</code></pre>
    <p>Then I had to manually add the times to a list.</p>
    <pre><code class="language-python">times1.append(time_taken)</code></pre>
    <p>And then calculate stats.</p>
    <pre><code class="language-python">import statistics

mean = statistics.mean(times1)
median = statistics.median(times1)</code></pre>
    <p>And you have to do this for every function you need to time.</p>
    <pre><code class="language-python">times2.append(time_taken)

times3.append(time_taken)

# and so on...</code></pre>
    <p>I wanted a super quick way to do this, that also made sense.</p>
    <p>Result:</p>
    <ul>
        <li>100% coverage of your code (you can time anything and everything)</li>
        <li>1-line setup</li>
        <li>thread safety</li>
        <li>deep statistical analysis, much better than <code>timeit</code></li>
        <li>native async support</li>
    </ul>
    <h2><code>@timethis</code> decorator</h2>
    <details>
        <summary>Without <code>timing</code> - <em>7 lines</em></summary>
        <div class="dropdown-content">
    <pre><code class="language-python">import time # 1
from typing import Any

times_my_function = [] # 2

def my_function() -&gt; tuple[Any, float]:
    start_time = time.time() # 3

    # whatever the function actually does

    end_time = time.time() # 4

    return function_result, end_time - start_time # 5

result, time_taken = my_function() # 6

times_my_function.append(time_taken) # 7</code></pre>
        </div>
    </details>
    <p>With <code>timing</code> - <em>2 lines</em></p>
    <pre><code class="language-python">from suitkaise.timing import timethis # 1

@timethis() # 2
def my_function():

    # whatever the function actually does

    return result

result = my_function()</code></pre>
    <ul>
        <li>you can just slap <code>@timethis()</code> on any function you need to time</li>
        <li>stored as a property of the function</li>
        <li>don&#x27;t have to edit a function to time it</li>
    </ul>
    <h2><code>TimeThis</code> context manager</h2>
    <p>This covers everything that <code>@timethis</code> doesn&#x27;t in a context manager pattern.</p>
    <details>
        <summary>Without <code>timing</code> - <em>6 lines</em></summary>
        <div class="dropdown-content">
    <pre><code class="language-python">import time # 1

times = [] # 2

start_time = time.time() # 3

# whatever you need to time

end_time = time.time() # 4

time_taken = end_time - start_time # 5
times.append(time_taken) # 6</code></pre>
        </div>
    </details>
    <p>With <code>timing</code> - <em>2 lines</em></p>
    <pre><code class="language-python">from suitkaise.timing import TimeThis # 1

with TimeThis() as timer: # 2

    # whatever you need to time

time_taken = timer.most_recent # 3</code></pre>
    <ul>
        <li>no manual tracking</li>
        <li>context manager makes it clear what is being timed</li>
        <li>error proof</li>
        <li>clear indication of what is being timed</li>
    </ul>
    <h2>Deep Statistical Analysis</h2>
    <p><code>timeit</code> gives you a single number. That&#x27;s not enough.</p>
    <p>You need mean, median, standard deviation, variance, and percentiles to actually understand performance.</p>
    <p>Without <code>timing</code> - <em>10+ lines</em></p>
    <pre><code class="language-python">import time
import statistics

times = []

for i in range(100):
    start = time.perf_counter()
    do_work()
    end = time.perf_counter()
    times.append(end - start)

mean = statistics.mean(times)
median = statistics.median(times)
stdev = statistics.stdev(times)

# percentiles? have fun
sorted_times = sorted(times)
p95 = sorted_times[int(0.95 * len(sorted_times))]</code></pre>
    <p>With <code>timing</code></p>
    <pre><code class="language-python">from suitkaise import timing

timer = timing.Sktimer()

for i in range(100):
    timer.start()
    do_work()
    timer.stop()

# all statistics instantly available
timer.mean
timer.median
timer.stdev
timer.variance
timer.min
timer.max
timer.percentile(95)
timer.percentile(99)</code></pre>
    <p>One object. Every stat you could want. No manual calculation.</p>
    <h2>Pause and Resume</h2>
    <p>You&#x27;re timing a database query, but you need to ask the user something in the middle.</p>
    <p>Without <code>timing</code></p>
    <pre><code class="language-python">import time

start = time.perf_counter()

results = database.query(&quot;SELECT * FROM users&quot;)

# pause timing... manually?
pause_start = time.perf_counter()
user_input = input(&quot;Export to CSV? (y/n): &quot;)
pause_end = time.perf_counter()
pause_duration = pause_end - pause_start

if user_input == &#x27;y&#x27;:
    export_to_csv(results)

end = time.perf_counter()

# manually subtract pause time
elapsed = (end - start) - pause_duration</code></pre>
    <p>With <code>timing</code></p>
    <pre><code class="language-python">from suitkaise import timing

timer = timing.Sktimer()
timer.start()

results = database.query(&quot;SELECT * FROM users&quot;)

timer.pause()
user_input = input(&quot;Export to CSV? (y/n): &quot;)
timer.resume()

if user_input == &#x27;y&#x27;:
    export_to_csv(results)

elapsed = timer.stop()  # user input time excluded</code></pre>
    <p><code>pause()</code> and <code>resume()</code>. That&#x27;s it. The timer handles the math.</p>
    <h2>Discard Bad Measurements</h2>
    <p>Sometimes things fail. You don&#x27;t want failed attempts polluting your statistics.</p>
    <p>Without <code>timing</code></p>
    <pre><code class="language-python">times = []

for i in range(100):
    start = time.perf_counter()
    try:
        result = unreliable_operation()
        end = time.perf_counter()
        times.append(end - start)
    except Exception:
        pass  # awkward - start was recorded, now what?</code></pre>
    <p>With <code>timing</code></p>
    <pre><code class="language-python">timer = timing.Sktimer()

for i in range(100):
    timer.start()
    try:
        result = unreliable_operation()
        timer.stop()  # success - record it
    except Exception:
        timer.discard()  # failure - forget it

# statistics only reflect successful operations</code></pre>
    <p><code>discard()</code> cleanly abandons the measurement. Your stats stay clean.</p>
    <h2>Thread Safety</h2>
    <p>Multiple threads timing the same thing? No problem.</p>
    <pre><code class="language-python">timer = timing.Sktimer()  # thread-safe by default

def worker():
    for _ in range(100):
        timer.start()
        do_work()
        timer.stop()

# spawn 4 threads...
# stats just work
print(timer.mean)</code></pre>
    <p><code>Sktimer</code> is thread-safe out of the box. Each thread gets its own session. Results aggregate automatically.</p>
    <h2>Lap Timing</h2>
    <p>Timing items in a loop? <code>lap()</code> is stop + start in one call.</p>
    <p>Without <code>timing</code></p>
    <pre><code class="language-python">times = []
start = time.perf_counter()

for item in items:
    process(item)
    now = time.perf_counter()
    times.append(now - start)
    start = now  # easy to forget this</code></pre>
    <p>With <code>timing</code></p>
    <pre><code class="language-python">timer = timing.Sktimer()
timer.start()

for item in items:
    process(item)
    timer.lap()  # records time, continues timing

timer.discard()  # clean up the last pending measurement</code></pre>
    <h2>Rolling Windows</h2>
    <p>Long-running server? Can&#x27;t keep every measurement forever.</p>
    <p>Without <code>timing</code></p>
    <pre><code class="language-python">from collections import deque

MAX_TIMES = 1000
times = deque(maxlen=MAX_TIMES)
lock = threading.Lock()

# now manually manage this everywhere</code></pre>
    <p>With <code>timing</code></p>
    <pre><code class="language-python">timer = timing.Sktimer(max_times=1000)

# that&#x27;s it - automatically keeps only the last 1000 measurements</code></pre>
    <p>One parameter. Memory bound. Statistics always reflect recent performance.</p>
    <h2>Threshold Filtering</h2>
    <p>Only care about slow operations? Filter out the fast ones automatically.</p>
    <pre><code class="language-python">@timing.timethis(threshold=0.1)
def handle_request():
    # only records times &gt;= 0.1 seconds
    ...</code></pre>
    <p>Fast operations are silently discarded. Your statistics focus on what matters.</p>
    <h2>Stacked Decorators</h2>
    <p>Want both combined stats AND per-function stats?</p>
    <pre><code class="language-python">perf_timer = timing.Sktimer()

@timing.timethis()             # per-function timer
@timing.timethis(perf_timer)   # shared timer
def db_read():
    ...

@timing.timethis()             # per-function timer
@timing.timethis(perf_timer)   # shared timer
def db_write():
    ...

# combined stats
print(perf_timer.mean)

# individual stats
print(db_read.timer.mean)
print(db_write.timer.mean)</code></pre>
    <p>Stack decorators. Each records independently. Zero manual list management.</p>
    <h2>Frozen Snapshots</h2>
    <p>Need to capture statistics at a point in time?</p>
    <pre><code class="language-python">snapshot = timer.get_statistics()

# timer continues recording...
timer.start()
do_more_work()
timer.stop()

# snapshot still has the old values
print(snapshot.mean)  # unchanged</code></pre>
    <p><code>get_statistics()</code> returns an immutable <code>TimerStats</code> object. Perfect for logging or reporting.</p>
    <h2><code>elapsed()</code> Just Works</h2>
    <p>Order doesn&#x27;t matter. Always returns positive.</p>
    <pre><code class="language-python">from suitkaise import timing

start = timing.time()
timing.sleep(1)
end = timing.time()

timing.elapsed(start, end)  # 1.0
timing.elapsed(end, start)  # 1.0 (same!)
timing.elapsed(start)       # uses current time</code></pre>
    <p>No more <code>abs()</code> everywhere. No more &quot;which one was first?&quot; bugs.</p>
    <h2>Async Support</h2>
    <pre><code class="language-python"># sync
timing.sleep(1)

# async
await timing.sleep.asynced()(1)</code></pre>
    <p>Same API. Just add <code>.asynced()</code> when you need it.</p>
    <p>This works with <code>TimeThis</code> too:</p>
    <pre><code class="language-python">async def fetch_all():
    async with TimeThis() as timer:
        await fetch_users()
        await fetch_orders()
    
    print(f&quot;Total: {timer.most_recent:.3f}s&quot;)</code></pre>
    <p>And with <code>@timethis</code>:</p>
    <pre><code class="language-python">@timethis()
async def fetch_data():
    async with aiohttp.ClientSession() as session:
        return await session.get(&quot;https://api.example.com&quot;)

await fetch_data()
print(fetch_data.timer.mean)</code></pre>
    <p>Sync and async, same interface. No separate implementations needed.</p>
    <h2>Works with <code>Share</code> â€” timing across processes</h2>
    <p><code>Sktimer</code> works natively inside <code>Share</code>. This means you can aggregate timing data across multiple processes without any extra code.</p>
    <pre><code class="language-python">from suitkaise.processing import Share, Pool, Skprocess
from suitkaise.timing import Sktimer

share = Share()
share.timer = Sktimer()

class TimedWorker(Skprocess):
    def __init__(self, share, data):
        self.share = share
        self.data = data
        self.process_config.runs = 1

    def __run__(self):
        self.share.timer.start()
        process(self.data)
        self.share.timer.stop()

pool = Pool(workers=4)
pool.star().map(TimedWorker, [(share, item) for item in work_items])

# all 4 processes contributed to the same timer
print(f&quot;Mean across all workers: {share.timer.mean:.3f}s&quot;)
print(f&quot;p95 across all workers: {share.timer.percentile(95):.3f}s&quot;)</code></pre>
    <p>Every process writes to the same timer. Stats aggregate automatically. No manual list management, no locks, no merging results.</p>
    <p><code>Skprocess</code> also has built-in timers for every lifecycle method -- access them via <code>process.__run__.timer</code>, <code>process.__prerun__.timer</code>, etc. These are <code>Sktimer</code> objects with all the same statistical depth.</p>
</section>
